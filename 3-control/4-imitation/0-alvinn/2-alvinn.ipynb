{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notes\n",
        "\n",
        "> Specifically, ALVINN is an artificial neural network designed to control the NAVLAB, the Carnegie Mellon autonomous navigation test vehicle.\n",
        "\n",
        "### Network Architecture\n",
        "\n",
        "![Screenshot 2024-11-06 at 12.57.22 PM.png](../../../images/Screenshot_2024-11-06_at_12.57.22_PM.png)\n",
        "\n",
        "ALVINN takes input in the form of the blue channel of a camera (because this channel has the highest contrast between road and non-road) and a range measurement input, as well as a road intensity feedback unit pulling from the previous inference run that measures if the road is getting higher or lower contrast from it’s environment.\n",
        "\n",
        "It uses these values to predict a linear representation of the curvature of the road, which it uses to determine the direction to turn in to move closer to the center of the road.\n",
        "\n",
        "### Training and Performance\n",
        "\n",
        "They need data from a variety of road conditions including different lighting and noise, which is hard to collect directly.\n",
        "\n",
        "Instead, they have a human drive around in a car and capture the input road images and driving commands.\n",
        "\n",
        "Then, they use a simulator to augment this dataset by generating new road images with more noise using transformations of images from this data.\n",
        "\n",
        "Since they trained on human driving data and learned a control policy to mimic human driving behavior, this is often considered the first behavior cloning paper.\n",
        "\n",
        "They set the road intensity unit input to a random activation level during early training to prevent the model from just learning to copy the input to the output (since real road intensity will be the same between images).\n",
        "\n",
        "By doing this, they basically allow the model to independently form a road intensity prediction and only factor in the previous intensity once it has learned to do this.\n",
        "\n",
        "> After 40 epochs of training on the 1200 simulated road snapshots, the network correctly dictates a tum curvature within two units of the correct answer approximately 90% of the time on novel simulated road images.\n",
        "\n",
        "### Network Representation\n",
        "\n",
        "> The representation developed by the network to perform the road following task depends dramatically on the characteristics of the training set.\n",
        "\n",
        "When the roads in the training set are all fixed with, the network features become overlapping road filters.\n",
        "\n",
        "When the roads are of varying lengths, the units start to be independent feature detectors, like one unit detecting the left edge of the road.\n",
        "\n",
        "### Discussion and Extensions\n",
        "\n",
        "> The distinct representations developed for different circumstances illustrate a key advantage provided by neural networks for autonomous navigation. Namely, in this paradigm the data, not the programmer, determines the salient image features crucial to accurate road navigation.\n",
        "\n",
        "An early demonstration feeling the fact that neural networks tune parameters far faster than humans can. They compare the 1 hour training time of ALVINN to the months spent by the CMU team to make features using traditional image processing techniques.\n",
        "\n",
        "> By interactively training the network on real road images taken as a human drives the NAVLAB, we hope to develop a system that adapts its processing to accommodate current circumstances.\n",
        "\n",
        "They further suggest behavior cloning as a way for the neural network to learn from humans.\n",
        "\n",
        "The network has to presented with enough variability in training to generalize properly.\n",
        "\n",
        "> In addition, the network must not solely be shown examples of accurate driving, but also how to recover (i.e. return to the road center) once a mistake has been made.\n",
        "\n",
        "When training with behavior cloning, the network needs to know how to operate in failure cases. If it isn’t explicitly trained in these environments, it won’t know what to do.\n",
        "\n",
        "> Another important advantage gained through the use of neural networks for autonomous navigation is the ease with which they assimilate data from independent sensors.\n",
        "\n",
        "Appreciating that neural networks can easily integrate any correlated data with a task to make predictions.\n",
        "\n",
        "> In the area of planning, interesting extensions include stopping for, or planning a path around, obstacles.\n",
        "\n",
        "> Beyond dealing with individual intersections, we would eventually like to integrate a map into the system to enable global point-to-point path planning.\n",
        "\n",
        "These really highlight why Tesla has always been a robotics company. Making autonomous vehicles is completely a robotics problem involving perception, planning, and control.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "> We are optimistic concerning the eventual contributions neural networks will make to the area of autonomous navigation.\n",
        "\n",
        "> We certainly believe it is important to begin researching and evaluating neural networks in real world situations, and we think autonomous navigation is an interesting application for such an approach.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
